# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gAVs3teOOx1O8s51vIg2168txPC6bf2Q
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from google.colab import files
uploaded=files.upload()

"""**LOADING DATASET**"""

import kagglehub
import pandas as pd


path = kagglehub.dataset_download("arshid/iris-flower-dataset")


print("Path to dataset files:", path)


csv_file_path = f"{path}/IRIS.csv"


try:
    data = pd.read_csv(csv_file_path, encoding='utf-8')
except UnicodeDecodeError:
    data = pd.read_csv(csv_file_path, encoding='ISO-8859-1')


print(data.head())

print("First 5 rows of the dataset:")
print(data.head())

print("Last 5 rows of the dataset:")
print(data.tail())

print("\nSummary of the dataset:")
print(data.info())

print("\nMissing values in each column:")
print(data.isnull().sum())

if "types" in data.columns:

    different types = data.sort_values(by="rare", ascending=False).head(10)
    print("\nTop rare types:")
    print(top_rare[["name", "rare"]])

    # Distribution of ratings
    plt.figure(figsize=(10, 6))
    sns.histplot(data["rating"], bins=20, kde=True, color="blue")
    plt.title("loaction")
    plt.xlabel("Rating")
    plt.ylabel("Frequency")
    plt.show()

    # Average rating per genre
    if "genre" in data.columns:
        avg_rating_per_genre = data.groupby("genre")["rating"].mean().sort_values(ascending=False)
        print("\nAverage rare per type:")
        print(avg_rating_per_type)

        # Plot average rating per genre
        plt.figure(figsize=(12, 6))
        avg_rating_per_genre.plot(kind="bar", color="orange")
        plt.title("Average Rare per type")
        plt.xlabel("Genre")
        plt.ylabel("Average Rare")
        plt.xticks(rotation=45)
        plt.show()
    else:
        print("\n'type' column not found in the dataset.")
else:
    print("\n'rare' column not found in the dataset.")

print(data.dtypes)

print(data)

data.info()

"""**DATA VISUALUIZATION**"""

plt.figure(figsize=(10, 6))
sns.barplot(x='species', y='sepal_length', data=data)
plt.title('Sepal Length by Species')
plt.xlabel('Species')
plt.ylabel('Sepal Length (cm)')
plt.show()

import matplotlib.pyplot as plt


species_counts = data['species'].value_counts()


plt.figure(figsize=(8, 8))
plt.pie(species_counts, labels=species_counts.index, autopct='%1.1f%%', startangle=90)
plt.title('Distribution of Iris Species')
plt.axis('equal')

import matplotlib.pyplot as plt


plt.figure(figsize=(10, 6))
plt.plot(data['sepal_length'], label='Sepal Length')
plt.plot(data['sepal_width'], label='Sepal Width')
plt.xlabel('Index')
plt.ylabel('Measurement (cm)')
plt.title('Sepal Length and Width')
plt.legend()
plt.grid(True)
plt.show()

"""**SPLITTING DATA**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from google.colab import files
import os
import zipfile


try:

    !kaggle datasets download -d arshid/iris-flower-dataset -p /content


    with zipfile.ZipFile('/content/iris-flower-dataset.zip', 'r') as zip_ref:
        zip_ref.extractall('/content')


    csv_file_path = "/content/IRIS.csv"
    data = pd.read_csv(csv_file_path)

except Exception as e:
    print(f"An error occurred: {e}")
    print("Dataset download failed. Using a sample dataset for demonstration.")


    data = pd.DataFrame({
        'sepal_length': [5.1, 4.9, 4.7, 4.6, 5.0],
        'sepal_width': [3.5, 3.0, 3.2, 3.1, 3.6],
        'petal_length': [1.4, 1.4, 1.3, 1.5, 1.4],
        'petal_width': [0.2, 0.2, 0.2, 0.2, 0.2],
        'species': ['setosa', 'setosa', 'setosa', 'setosa', 'setosa']
    })


print("First 5 rows of the dataset:")
print(data.head())


print("Last 5 rows of the dataset:")
print(data.tail())


print("\nSummary of the dataset:")
print(data.info())


print("\nMissing values in each column:")
print(data.isnull().sum())


print("\nData types of each column:")
print(data.dtypes)

"""**MODEL**"""

!pip install catboost

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
csv_file_path = "IRIS.csv"


try:
    data = pd.read_csv(csv_file_path)
except Exception as e:
    print(f"Error loading dataset: {e}")
    exit()
print("First 5 rows of the dataset:")
print(data.head())


label_encoder = LabelEncoder()
data['species'] = label_encoder.fit_transform(data['species'])


features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
X = data[features]
y = data['species']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


models = {
    'Logistic Regression': LogisticRegression(max_iter=200),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'Extended Gradient Boosting': XGBClassifier(),
    'Light Gradient Boosting': LGBMClassifier(),
    'Cat Boosting': CatBoostClassifier(silent=True),
    'K Nearest Neighbors': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier()
}


model_results = {}


for idx, (name, model) in enumerate(models.items()):
    try:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        model_results[name] = accuracy
    except Exception as e:
        print(f"Error training {name}: {e}")
        model_results[name] = None


for model_name, accuracy in model_results.items():
    if accuracy is not None:
        print(f"{model_name}: Accuracy = {accuracy:.2f}")
    else:
        print(f"{model_name}: Failed to train")
